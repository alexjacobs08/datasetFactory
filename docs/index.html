<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>datasetFactory - Synthetic RAG Evaluation Datasets</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --bg: #2B2B2B;
            --surface: #313335;
            --surface-light: #3C3F41;
            --border: #555555;
            --text: #ECECEC;
            --text-dim: #B0B0B0;
            --accent: #E8B558;
            --accent-dim: #D9A84A;
            --warning: #E06C75;
            --code: #1E1E1E;
            --green: #98C379;
        }

        body {
            font-family: 'Courier New', 'Courier', monospace;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            font-size: 15px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        header {
            margin-bottom: 60px;
            padding-bottom: 30px;
            border-bottom: 2px solid var(--border);
        }

        h1 {
            font-size: 2.5em;
            color: #FFA500;
            margin-bottom: 10px;
            font-weight: normal;
            letter-spacing: -1px;
        }

        .tagline {
            color: var(--text-dim);
            font-size: 1.1em;
            margin-bottom: 20px;
        }

        .install {
            background: var(--surface);
            padding: 20px;
            border-radius: 4px;
            border: 1px solid var(--border);
            margin: 30px 0;
            position: relative;
        }

        .install::before {
            content: '$ ';
            color: var(--accent);
        }

        .install code {
            color: var(--text);
            font-family: inherit;
        }

        .section {
            margin: 50px 0;
        }

        h2 {
            color: var(--accent);
            font-size: 1.5em;
            margin-bottom: 20px;
            font-weight: normal;
        }

        h2::before {
            content: '> ';
            color: #FFA500;
            font-weight: bold;
        }

        p {
            margin-bottom: 15px;
            color: var(--text-dim);
        }

        .problem-list {
            background: var(--surface);
            padding: 20px;
            border-left: 4px solid var(--warning);
            margin: 20px 0;
            box-shadow: 0 2px 6px rgba(0,0,0,0.2);
        }

        .problem-list li {
            margin: 10px 0;
            padding-left: 20px;
            color: var(--text);
        }

        .problem-list li::marker {
            content: '• ';
            color: var(--warning);
        }

        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .feature {
            background: var(--surface);
            padding: 20px;
            border-radius: 4px;
            border: 1px solid var(--border);
            transition: all 0.3s;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }

        .feature:hover {
            border-color: var(--accent);
            box-shadow: 0 4px 8px rgba(0,0,0,0.3);
            transform: translateY(-2px);
        }

        .feature h3 {
            color: var(--accent);
            font-size: 1.1em;
            margin-bottom: 10px;
            font-weight: normal;
        }

        .feature p {
            font-size: 0.95em;
        }

        .code-example {
            background: var(--code);
            padding: 20px;
            border-radius: 4px;
            border: 1px solid var(--border);
            margin: 20px 0;
            overflow-x: auto;
            box-shadow: 0 2px 8px rgba(0,0,0,0.3);
        }

        .code-example pre {
            color: var(--text);
            font-family: inherit;
            line-height: 1.5;
        }

        .code-example .comment {
            color: #7A7A7A;
            font-style: italic;
        }

        .code-example .string {
            color: #98C379;
        }

        .code-example .keyword {
            color: #61AFEF;
        }

        .stats {
            display: flex;
            gap: 30px;
            margin: 30px 0;
            flex-wrap: wrap;
        }

        .stat {
            background: var(--surface);
            padding: 15px 25px;
            border-radius: 4px;
            border: 1px solid var(--border);
            flex: 1;
            min-width: 150px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }

        .stat-value {
            font-size: 2em;
            color: #FFA500;
            display: block;
        }

        .stat-label {
            color: var(--text-dim);
            font-size: 0.9em;
        }

        .cta {
            display: inline-block;
            background: #FFA500;
            color: #1A1A1A;
            padding: 12px 30px;
            text-decoration: none;
            border-radius: 4px;
            margin: 10px 10px 10px 0;
            font-weight: bold;
            transition: all 0.3s;
            box-shadow: 0 2px 6px rgba(255, 165, 0, 0.3);
        }

        .cta:hover {
            background: #FF9500;
            box-shadow: 0 4px 12px rgba(255, 165, 0, 0.5);
            transform: translateY(-2px);
        }

        .cta-secondary {
            background: transparent;
            border: 2px solid #FFA500;
            color: #FFA500;
            box-shadow: 0 2px 6px rgba(255, 165, 0, 0.2);
        }

        .cta-secondary:hover {
            background: rgba(255, 165, 0, 0.1);
            box-shadow: 0 4px 12px rgba(255, 165, 0, 0.4);
        }

        .cta-blog {
            background: transparent;
            border: 2px solid var(--green);
            color: var(--green);
            box-shadow: 0 2px 6px rgba(152, 195, 121, 0.2);
        }

        .cta-blog:hover {
            background: rgba(152, 195, 121, 0.1);
            box-shadow: 0 4px 12px rgba(152, 195, 121, 0.4);
            color: var(--green);
            text-decoration: none;
        }

        footer {
            margin-top: 80px;
            padding-top: 30px;
            border-top: 1px solid var(--border);
            color: var(--text-dim);
            text-align: center;
            font-size: 0.9em;
        }

        .terminal-prompt {
            color: var(--green);
            font-weight: bold;
        }

        .blink {
            animation: blink 1s infinite;
        }

        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0; }
        }

        ul {
            list-style: none;
        }

        .footer a {
            color: #FFA500;
            text-decoration: none;
            transition: color 0.2s;
        }

        .footer a:hover {
            color: #FFB732;
            text-decoration: underline;
        }
        
        .cta, .cta-secondary, .cta-blog {
            text-decoration: none !important;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2em;
            }
            
            .feature-grid {
                grid-template-columns: 1fr;
            }
            
            .stats {
                flex-direction: column;
            }
        }
    </style>
    
    <!-- Privacy-friendly analytics by Plausible -->
    <script async src="https://plausible.io/js/pa-hAlRGoKz0_jPZW8_CDvtw.js"></script>
    <script>
      window.plausible=window.plausible||function(){(plausible.q=plausible.q||[]).push(arguments)},plausible.init=plausible.init||function(i){plausible.o=i||{}};
      plausible.init()
    </script>
</head>
<body>
    <div class="container">
        <header>
            <h1>datasetFactory</h1>
            <p class="tagline">Generate scaled synthetic datasets for RAG evaluation</p>
            <div style="margin-top: 20px;">
                <a href="https://github.com/alexjacobs08/datasetFactory" class="cta">View on GitHub</a>
                <a href="https://github.com/alexjacobs08/datasetFactory/tree/main/examples" class="cta cta-secondary">See Examples</a>
                <a href="https://github.com/alexjacobs08/datasetFactory/tree/main/datasets" class="cta cta-secondary">View Datasets</a>
            </div>
        </header>

        <section class="section">
            <h2>The Problem with RAG Evaluation</h2>
            <div class="problem-list">
                <ul>
                    <li><strong>Data pollution:</strong> Benchmark datasets are in training data. Foundation models have seen MS MARCO, BeIR. Generation results are polluted by training data.</li>
                    <li><strong>High-fidelity filtering:</strong> Production RAG needs complex metadata filters. Date ranges, nested categories, numerical thresholds. Existing retrieval datasets have a category field and maybe some tags.</li>
                </ul>
            </div>
            <p style="font-size: 1.1em; margin-top: 25px; color: var(--text);"><strong>So I built this.</strong> Generate complete RAG evaluation datasets from a single text prompt. Fresh synthetic data at any scale you need.</p>
            
            <p style="margin-top: 20px;">This lets you test what actually matters:</p>
            <ul style="margin-left: 20px; color: var(--text);">
                <li style="margin: 10px 0;">→ RAG systems without training data contamination</li>
                <li style="margin: 10px 0;">→ How vector databases handle complex filters</li>
                <li style="margin: 10px 0;">→ Pre-filter vs post-filter performance</li>
                <li style="margin: 10px 0;">→ Retrieval quality degradation with corpus size</li>
                <li style="margin: 10px 0;">→ Metadata selectivity edge cases</li>
            </ul>
        </section>

        <section class="section">
            <h2>Generate a Dataset</h2>
            <div class="code-example">
<pre><span class="terminal-prompt">$</span> dataset-factory generate \
  --prompt <span class="string">"A gold rush town in the Yukon during the 1890s"</span> \
  --documents <span class="keyword">1000</span> \
  --queries <span class="keyword">100</span> \
  --output output/goldrush

<span class="comment"># Output:
# ✓ 1,000 unique documents (268-12,631 tokens)
# ✓ 100 queries with ground truth
# ✓ Rich metadata: settlements, roles, dates, activities
# ✓ Cost tracking: $0.46 with Groq</span></pre>
            </div>
        </section>

        <div class="stats">
            <div class="stat">
                <span class="stat-value">1M+</span>
                <span class="stat-label">documents supported</span>
            </div>
            <div class="stat">
                <span class="stat-value">7-25</span>
                <span class="stat-label">document types</span>
            </div>
            <div class="stat">
                <span class="stat-value">$0.46</span>
                <span class="stat-label">per 1K docs (Llama 3.1 8B via Groq)</span>
            </div>
        </div>

        <section class="section">
            <h2>How It Works</h2>
            <div class="feature-grid">
                <div class="feature">
                    <h3>1. Config Generation</h3>
                    <p>LLM analyzes your prompt and creates a schema. Document types, metadata fields, value distributions.</p>
                </div>
                <div class="feature">
                    <h3>2. World Building</h3>
                    <p>Generates 2000 words of domain context. History, entities, terminology, relationships. Used for all documents.</p>
                </div>
                <div class="feature">
                    <h3>3. Document Generation</h3>
                    <p>Each doc gets random metadata from config. LLM generates unique content. No templates. 5 prompt variations for diversity.</p>
                </div>
                <div class="feature">
                    <h3>4. Query Generation</h3>
                    <p>Analyzes dataset statistics. Picks filter selectivity. Generates queries from actual document content with known ground truth.</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2>Features</h2>
            <div class="feature-grid">
                <div class="feature">
                    <h3>Variable Length</h3>
                    <p>400-40,000 token documents. Short reports to comprehensive audits. Realistic length distributions.</p>
                </div>
                <div class="feature">
                    <h3>Rich Metadata</h3>
                    <p>Temporal, categorical, numerical, hierarchical fields. Zipfian and uniform distributions. Precise filter control.</p>
                </div>
                <div class="feature">
                    <h3>Selective Queries</h3>
                    <p>Control selectivity from 0.1% (ultra-specific) to 10%+ (broad). Test pre-filter vs post-filter performance.</p>
                </div>
                <div class="feature">
                    <h3>Cost Tracking</h3>
                    <p>Real-time cost monitoring per phase. Detailed breakdowns. Works across resume sessions.</p>
                </div>
                <div class="feature">
                    <h3>Resumable</h3>
                    <p>Pause and resume at any time. Streams to JSONL. Memory efficient at any scale.</p>
                </div>
                <div class="feature">
                    <h3>Multi-LLM</h3>
                    <p>Groq, Gemini, OpenAI, Anthropic. Smart rate limiting. Auto-concurrency adjustment.</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2>Risks</h2>
            <p>Using an LLM to generate eval data for LLM systems is weird. Hallucination is the goal here, which feels like an anti-pattern.</p>
            
            <p><strong>Biggest risk:</strong> Similar documents. Even with high temperature and prompt variations, you might get semantically identical documents. A hundred prospector journals that all sound the same.</p>
            
            <p><strong>Internal consistency:</strong> No guarantee the LLM maintains coherent facts across thousands of documents. It might contradict itself.</p>
            
            <p><strong>But:</strong> As long as you use the same dataset to compare multiple systems, the comparison is still fair. Weird artifacts affect all systems equally. You're measuring relative performance, not absolute quality on some perfect benchmark.</p>
        </section>

        <section class="section">
            <h2>Example Datasets</h2>
            <div class="code-example">
<pre><span class="comment"># Historical</span>
<span class="terminal-prompt">$</span> <span class="keyword">--prompt</span> <span class="string">"Yukon gold rush town during the 1890s"</span>

<span class="comment"># Corporate</span>
<span class="terminal-prompt">$</span> <span class="keyword">--prompt</span> <span class="string">"Dystopian tech megacorp with surveillance and AI incidents"</span>

<span class="comment"># Scientific</span>
<span class="terminal-prompt">$</span> <span class="keyword">--prompt</span> <span class="string">"Biomedical research papers and clinical trials"</span>

<span class="comment"># Legal</span>
<span class="terminal-prompt">$</span> <span class="keyword">--prompt</span> <span class="string">"Legal contracts and case law from various jurisdictions"</span>

<span class="comment"># E-commerce</span>
<span class="terminal-prompt">$</span> <span class="keyword">--prompt</span> <span class="string">"Product listings with reviews and specifications"</span></pre>
            </div>
        </section>

        <section class="section">
            <h2>Get Started</h2>
            <div class="code-example">
<pre><span class="comment"># Install</span>
<span class="terminal-prompt">$</span> uv pip install dataset-factory

<span class="comment"># Set API key (supports Groq, Gemini, OpenAI, Anthropic)</span>
<span class="terminal-prompt">$</span> echo <span class="string">"GROQ_API_KEY=your_key"</span> > .env
<span class="terminal-prompt">$</span> <span class="comment"># or GEMINI_API_KEY, OPENAI_API_KEY, ANTHROPIC_API_KEY</span>

<span class="comment"># Generate with your chosen provider</span>
<span class="terminal-prompt">$</span> dataset-factory generate \
  --prompt <span class="string">"your domain description"</span> \
  --documents <span class="keyword">1000</span> \
  --queries <span class="keyword">100</span> \
  --output output/my_dataset</pre>
            </div>
            <div style="margin-top: 30px;">
                <a href="https://github.com/alexjacobs08/datasetFactory#-quick-start" class="cta">Quick Start</a>
                <a href="https://alex-jacobs.com" class="cta cta-blog">read my blog</a>
            </div>
        </section>

        <footer class="footer">
            <p>Built by <a href="https://github.com/alexjacobs08">Alex Jacobs</a> | Licensed under AGPL-3.0</p>
            <p style="margin-top: 10px;">On-demand scaled synthetic data generation is just freaking cool.</p>
        </footer>
    </div>
</body>
</html>

